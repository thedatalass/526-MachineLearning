{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading 20news dataset. This may take a few minutes.\n",
      "INFO:sklearn.datasets.twenty_newsgroups:Downloading 20news dataset. This may take a few minutes.\n",
      "Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n",
      "INFO:sklearn.datasets.twenty_newsgroups:Downloading dataset from https://ndownloader.figshare.com/files/5975967 (14 MB)\n"
     ]
    }
   ],
   "source": [
    "#We will use Naive Bayes for text classification for spam filtering\n",
    "#Code adapted for Python 3.6.1 from 2013 book \"Learning Scikit-learn: Machine Learning in Python\" by Raul Garreta\n",
    "#May 9, 2017 by L Kahn\n",
    "\n",
    "#Get the data\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "news = fetch_20newsgroups(subset='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list,\n",
       " numpy.ndarray,\n",
       " ['alt.atheism',\n",
       "  'comp.graphics',\n",
       "  'comp.os.ms-windows.misc',\n",
       "  'comp.sys.ibm.pc.hardware',\n",
       "  'comp.sys.mac.hardware',\n",
       "  'comp.windows.x',\n",
       "  'misc.forsale',\n",
       "  'rec.autos',\n",
       "  'rec.motorcycles',\n",
       "  'rec.sport.baseball',\n",
       "  'rec.sport.hockey',\n",
       "  'sci.crypt',\n",
       "  'sci.electronics',\n",
       "  'sci.med',\n",
       "  'sci.space',\n",
       "  'soc.religion.christian',\n",
       "  'talk.politics.guns',\n",
       "  'talk.politics.mideast',\n",
       "  'talk.politics.misc',\n",
       "  'talk.religion.misc'])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(news.data), type(news.target), news.target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18846"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(news.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18846"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(news.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Machine learning algorithms only work on numeric data so we convert the text dataset to numeric dataset\n",
    "#But, our first set is to split the data into training and test sets\n",
    "#Since the loaded data is already in random order, we only have to split the data into 75 % for training & 25% for testing\n",
    "SPLIT_PERC = 0.75\n",
    "split_size = int(len(news.data)*SPLIT_PERC)\n",
    "X_train = news.data[:split_size]\n",
    "X_test = news.data[split_size:]\n",
    "y_train = news.target[:split_size]\n",
    "y_test = news.target[split_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#We're going to use a Pipeline class which constructs a compound classifier, which consists of several vectorizers\n",
    "#and classifiers\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, HashingVectorizer, CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_1 = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_2 = Pipeline([\n",
    "    ('vect', HashingVectorizer(non_negative=True)),\n",
    "    ('clf', MultinomialNB()),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "clf_3 = Pipeline([\n",
    "    ('vect', TfidfVectorizer()),\n",
    "    ('clf', MultinomialNB()),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lkahn\\AppData\\Local\\Continuum\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#Next we define a function that takes a classifier and performs a K-fold cross-validation over specified\n",
    "#X and y values\n",
    "from sklearn.cross_validation import cross_val_score as cv, KFold\n",
    "from scipy.stats import sem\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_cross_validation(clf, X_train, y_train, K):\n",
    "    #create a k-fold cross validation iterator of k=5 folds\n",
    "    cv = KFold(len(y), K, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function sklearn.cross_validation.cross_val_score>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "evaluate_cross_validation() got an unexpected keyword argument 'cv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-570d0a563f66>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#by default the score used is the one returned by score (accuracy)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate_cross_validation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclf_1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mevaluate_cross_validation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m print (\"Mean score: {0:.3*evaluate_cross_validation} (+/-{1:.3*evaluate_cross_validation})\").format(\n\u001b[0;32m      5\u001b[0m     np.mean(scores), sem(scores))\n",
      "\u001b[1;31mTypeError\u001b[0m: evaluate_cross_validation() got an unexpected keyword argument 'cv'"
     ]
    }
   ],
   "source": [
    "#by default the score used is the one returned by score (accuracy)\n",
    "scores = evaluate_cross_validation(clf_1, X_train, cv=evaluate_cross_validation)\n",
    "print (scores)\n",
    "print (\"Mean score: {0:.3*evaluate_cross_validation} (+/-{1:.3*evaluate_cross_validation})\").format(\n",
    "    np.mean(scores), sem(scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
